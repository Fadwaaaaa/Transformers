{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d520b38",
   "metadata": {},
   "source": [
    "# NLP TP - TRANSFORMERS :         \n",
    "\n",
    "    . Sentiment Analysis\n",
    "    . Text Generation\n",
    "    . Name Entity Recognition\n",
    "    . Question Answering\n",
    "    . Filling masked text\n",
    "    . Summarization\n",
    "    . Translation\n",
    "    . Feature Extraction \n",
    "                                                                                                       Fadwa Saoiabi :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeebe04",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725748f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, with score: 0.9991\n",
      "label: POSITIVE, with score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis English\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = nlp(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = nlp(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5250319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, with score: 0.9971\n",
      "label: POSITIVE, with score: 0.8181\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis french\n",
    "\n",
    "result = nlp(\"Je suis vraiment fatiguée\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = nlp(\"Je me sens bien\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8860830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 star, with score: 0.6346\n",
      "label: 5 stars, with score: 0.8547\n"
     ]
    }
   ],
   "source": [
    "#Texte en anglais with model\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "result = nlp(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = nlp(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3deb736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2 stars, with score: 0.4522\n",
      "label: 5 stars, with score: 0.7895\n"
     ]
    }
   ],
   "source": [
    "#Texte en français\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "result = nlp(\"Je suis vraiment fatiguée\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = nlp(\"Je suis au top de ma forme\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6aa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5 stars, with score: 0.6108\n",
      "label: 1 star, with score: 0.2798\n"
     ]
    }
   ],
   "source": [
    "#Texte en arabe \n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "result = nlp(\"أنا أحبك كثيرا\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "result = nlp(\"أكرهك\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b44f71",
   "metadata": {},
   "source": [
    "# Text Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4442e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'As far as I am concerned, I will be the first to admit that I am not a fan of the idea of a \"free market.\" I think that the idea of a free market is a bit of a stretch. I think that the idea'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "print(text_generator(\"As far as I am concerned, I will\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb89d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'My name is \"S. S. \". I am a \"S. S. \". I am a \"S. S. \". I am a \"S. S. '}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'هذه الصفحة تحتوي على جميع ما يمكن أن تكون عليه من قبل، ولكن هذا لا يعني أن يكون الكتاب أفضل من ذلك، ولكن هذا لا يستحق أن يكون أفضل من ذلك.\"\\n\"لم يعجبني الكتاب كثيراً ، ربما كان مملاً جداً ، ربما'}]\n"
     ]
    }
   ],
   "source": [
    "text_generator_eng = pipeline(\"text-generation\",model=\"xlnet-base-cased\")\n",
    "print(text_generator_eng(\"My name is\", max_length=50, do_sample=False))\n",
    "\n",
    "text_generator_ara = pipeline(\"text-generation\",model=\"mofawzy/gpt2-arabic-sentence-generator\")\n",
    "print(text_generator_ara(\"هذه الصفحة تحتوي على جميع\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15417822",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598ffd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Liana Barrientos, 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree\" She has declared \"I do\" five more times, sometimes within two weeks of each other .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents\"\"\"\n",
    "\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4338784",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "839cae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Übersetzung ist die Aufgabe, einen Text von einer Sprache in eine andere zu übersetzen.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_de\")\n",
    "print(translator(\"Translation is the task of translating a text from one language to another. \", max_length=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a390b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Hugging Face est une entreprise technologique basée à New York et à Paris.</s>\n"
     ]
    }
   ],
   "source": [
    "#Translation using a model and a tokenizer from english to french.\n",
    "\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "inputs = tokenizer.encode(\"translate English to French: Hugging Face is a technology company based in New York and Paris\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b6fdbd",
   "metadata": {},
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e72d5861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-ORG', 'score': 0.9995786, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}, {'entity': 'I-ORG', 'score': 0.9909764, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}, {'entity': 'I-ORG', 'score': 0.9982225, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}, {'entity': 'I-ORG', 'score': 0.99948806, 'index': 4, 'word': 'Inc', 'start': 13, 'end': 16}, {'entity': 'I-LOC', 'score': 0.99943453, 'index': 11, 'word': 'New', 'start': 40, 'end': 43}, {'entity': 'I-LOC', 'score': 0.9993196, 'index': 12, 'word': 'York', 'start': 44, 'end': 48}, {'entity': 'I-LOC', 'score': 0.9993794, 'index': 13, 'word': 'City', 'start': 49, 'end': 53}, {'entity': 'I-LOC', 'score': 0.98625827, 'index': 19, 'word': 'D', 'start': 79, 'end': 80}, {'entity': 'I-LOC', 'score': 0.95142704, 'index': 20, 'word': '##UM', 'start': 80, 'end': 82}, {'entity': 'I-LOC', 'score': 0.93365914, 'index': 21, 'word': '##BO', 'start': 82, 'end': 84}, {'entity': 'I-LOC', 'score': 0.9761654, 'index': 28, 'word': 'Manhattan', 'start': 114, 'end': 123}, {'entity': 'I-LOC', 'score': 0.9914629, 'index': 29, 'word': 'Bridge', 'start': 124, 'end': 130}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\")\n",
    "\n",
    "Sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.\"\n",
    "\n",
    "print(nlp(Sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8da7f",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c16ca48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.49223577976226807, 'start': 141, 'end': 173, 'answer': 'she dreams of becoming a teacher'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"question-answering\")\n",
    "\n",
    "context = \"\"\"The boys in the village attend school every day. When Tina passes by them, she feels so sad and she wishes she could study like them because she dreams of becoming a teacher. Tina really knows the value of education and always says to her: “I will let my children study”. If all the children think in the same way, there will be less illiteracy among the future generations.\"\"\"\n",
    "\n",
    "print(nlp(question=\"Why Tina feels sad?\", context=context))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57af151",
   "metadata": {},
   "source": [
    "# Filling masked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "277f6fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'The boys in the village pray every day.', 'score': 0.40567484498023987, 'token': 10745, 'token_str': ' pray'}, {'sequence': 'The boys in the village suffer every day.', 'score': 0.03357984870672226, 'token': 6297, 'token_str': ' suffer'}, {'sequence': 'The boys in the village train every day.', 'score': 0.025151127949357033, 'token': 2341, 'token_str': ' train'}, {'sequence': 'The boys in the village cry every day.', 'score': 0.023954305797815323, 'token': 8930, 'token_str': ' cry'}, {'sequence': 'The boys in the village die every day.', 'score': 0.023221848532557487, 'token': 1597, 'token_str': ' die'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"fill-mask\")\n",
    "print(nlp(f\"The boys in the village {nlp.tokenizer.mask_token} every day.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefcf5d",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "622887ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.7959, -1.0001, -0.3122,  ...,  0.1940, -0.4849, -0.7758],\n",
      "        [-1.0121, -0.1321, -0.1315,  ..., -0.2003,  0.2946, -0.5103]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "sentences = ['Instagram is an American photo and video sharing social networking service.','Created by Kevin Systrom and Mike Krieger']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/distilbert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/distilbert-base-nli-mean-tokens')\n",
    "\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "model_output = model(**encoded_input)\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings :\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad598ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Instagram is an American photo and video sharing social networking service created by Kevin Systrom and Mike Krieger. In April 2012\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
